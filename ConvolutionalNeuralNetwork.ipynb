{
  "cells": [
    {
      "metadata": {
        "nbpresent": {
          "id": "138d1a78-02e2-4bd6-a20e-07b83f303563"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport sys\nimport time\n\nimport cntk as C\n\n%matplotlib inline",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Select the right target device when this notebook is being tested:\nif 'TEST_DEVICE' in os.environ:\n    if os.environ['TEST_DEVICE'] == 'cpu':\n        C.device.try_set_default_device(C.device.cpu())\n    else:\n        C.device.try_set_default_device(C.device.gpu(0))",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Test for CNTK version\nif not C.__version__ == \"2.0\":\n    raise Exception(\"work with 2.0. Current Version: \" + C.__version__) ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "work with 2.0. Current Version: 2.5.1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5ab7d8303df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test for CNTK version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"2.0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"work with 2.0. Current Version: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mException\u001b[0m: work with 2.0. Current Version: 2.5.1"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Ensure we always get the same amount of randomness\nnp.random.seed(0)\nC.cntk_py.set_fixed_random_seed(1)\nC.cntk_py.force_deterministic_algorithms()\n\n# Define the data dimensions\ninput_dim_model = (1, 28, 28)    # images are 28 x 28 with 1 channel of color (gray)\ninput_dim = 28*28                # used by readers to treat input data as a vector\nnum_output_classes = 10",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Read a CTF formatted text using the CTF deserializer from a file\ndef create_reader(path, is_training, input_dim, num_label_classes):\n    \n    ctf = C.io.CTFDeserializer(path, C.io.StreamDefs(\n          labels=C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n          features=C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)))\n                          \n    return C.io.MinibatchSource(ctf,\n        randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Ensure the training and test data is available\n# We search in two locations in the toolkit for the cached MNIST data set.\n\ndata_found=False # A flag to indicate if train/test data found in local cache\nfor data_dir in [os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n                 os.path.join(\"data\", \"MNIST\")]:\n    \n    train_file=os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n    test_file=os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n    \n    if os.path.isfile(train_file) and os.path.isfile(test_file):\n        data_found=True\n        break\n        \nif not data_found:\n    raise ValueError(\"Please generate the data by completing Lab1_MNIST_DataLoader\")\n    \nprint(\"Data directory is {0}\".format(data_dir))",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Data directory is data/MNIST\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x = C.input_variable(input_dim_model)\ny = C.input_variable(num_output_classes)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# function to build model\n\ndef create_model(features):\n    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n            h = features\n            h = C.layers.Convolution2D(filter_shape=(5,5), \n                                       num_filters=8, \n                                       strides=(2,2), \n                                       pad=True, name='first_conv')(h)\n            h = C.layers.Convolution2D(filter_shape=(5,5), \n                                       num_filters=16, \n                                       strides=(2,2), \n                                       pad=True, name='second_conv')(h)\n            r = C.layers.Dense(num_output_classes, activation=None, name='classify')(h)\n            return r",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create the model\nz = create_model(x)\n\n# Print the output shapes / parameters of different components\nprint(\"Output Shape of the first convolution layer:\", z.first_conv.shape)\nprint(\"Bias value of the last dense layer:\", z.classify.b.value)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Output Shape of the first convolution layer: (8, 14, 14)\nBias value of the last dense layer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Number of parameters in the network\nC.logging.log_number_of_parameters(z)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training 11274 parameters in 6 parameter tensors.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def create_criterion_function(model, labels):\n    loss = C.cross_entropy_with_softmax(model, labels)\n    errs = C.classification_error(model, labels)\n    return loss, errs # (model, labels) -> (loss, error metric)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# utility function to compute the moving average sum.\n# implementation is possible with np.cumsum() function\ndef moving_average(a, w=5):\n    if len(a) < w:\n        return a[:]    # Need to send a copy of the array\n    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n\n\n# Defines a utility that prints the training progress\ndef print_training_progress(trainer, mb, frequency, verbose=1):\n    training_loss = \"NA\"\n    eval_error = \"NA\"\n\n    if mb%frequency == 0:\n        training_loss = trainer.previous_minibatch_loss_average\n        eval_error = trainer.previous_minibatch_evaluation_average\n        if verbose: \n            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n        \n    return mb, training_loss, eval_error",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def train_test(train_reader, test_reader, model_func, num_sweeps_to_train_with=10):\n    \n    # Instantiate the model function; x is the input (feature) variable \n    # We will scale the input image pixels within 0-1 range by dividing all input value by 255.\n    model = model_func(x/255)\n    \n    # Instantiate the loss and error function\n    loss, label_error = create_criterion_function(model, y)\n    \n    # Instantiate the trainer object to drive the model training\n    learning_rate = 0.2\n    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n    learner = C.sgd(z.parameters, lr_schedule)\n    trainer = C.Trainer(z, (loss, label_error), [learner])\n    \n    # Initialize the parameters for the trainer\n    minibatch_size = 64\n    num_samples_per_sweep = 60000\n    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n    \n    # Map the data streams to the input and labels.\n    input_map={\n        y  : train_reader.streams.labels,\n        x  : train_reader.streams.features\n    } \n    \n    training_progress_output_freq = 500\n     \n    # Start a timer\n    start = time.time()\n\n    for i in range(0, int(num_minibatches_to_train)):\n        # Read a mini batch from the training data file\n        data=train_reader.next_minibatch(minibatch_size, input_map=input_map) \n        trainer.train_minibatch(data)\n        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n     \n    # Print training time\n    print(\"Training took {:.1f} sec\".format(time.time() - start))\n    \n    # Test the model\n    test_input_map = {\n        y  : test_reader.streams.labels,\n        x  : test_reader.streams.features\n    }\n\n    # Test data for trained model\n    test_minibatch_size = 512\n    num_samples = 10000\n    num_minibatches_to_test = num_samples // test_minibatch_size\n\n    test_result = 0.0   \n\n    for i in range(num_minibatches_to_test):\n    \n        # We are loading test data in batches specified by test_minibatch_size\n        # Each data point in the minibatch is a MNIST digit image of 784 dimensions \n        # with one pixel per dimension that we will encode / decode with the \n        # trained model.\n        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n        eval_error = trainer.test_minibatch(data)\n        test_result = test_result + eval_error\n\n    # Average of evaluation errors of all test minibatches\n    print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def do_train_test():\n    global z\n    z = create_model(x)\n    reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n    reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n    train_test(reader_train, reader_test, z)\n    \ndo_train_test()",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Minibatch: 0, Loss: 2.3062, Error: 92.19%\nMinibatch: 500, Loss: 0.1375, Error: 1.56%\nMinibatch: 1000, Loss: 0.0861, Error: 3.12%\nMinibatch: 1500, Loss: 0.0680, Error: 3.12%\nMinibatch: 2000, Loss: 0.0268, Error: 0.00%\nMinibatch: 2500, Loss: 0.0136, Error: 0.00%\nMinibatch: 3000, Loss: 0.0298, Error: 1.56%\nMinibatch: 3500, Loss: 0.1896, Error: 7.81%\nMinibatch: 4000, Loss: 0.0080, Error: 0.00%\nMinibatch: 4500, Loss: 0.0551, Error: 3.12%\nMinibatch: 5000, Loss: 0.0121, Error: 0.00%\nMinibatch: 5500, Loss: 0.0330, Error: 1.56%\nMinibatch: 6000, Loss: 0.0059, Error: 0.00%\nMinibatch: 6500, Loss: 0.0208, Error: 0.00%\nMinibatch: 7000, Loss: 0.0902, Error: 3.12%\nMinibatch: 7500, Loss: 0.0088, Error: 0.00%\nMinibatch: 8000, Loss: 0.0204, Error: 1.56%\nMinibatch: 8500, Loss: 0.0118, Error: 0.00%\nMinibatch: 9000, Loss: 0.0312, Error: 1.56%\nTraining took 768.3 sec\nAverage test error: 1.39%\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Bias value of the last dense layer:\", z.classify.b.value)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Bias value of the last dense layer: [-0.0446194  -0.01802263  0.03951858 -0.09530807 -0.01014417 -0.02689751\n -0.04643578 -0.09791499  0.29827267  0.00151422]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "out = C.softmax(z)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Read the data for evaluation\nreader_eval=create_reader(test_file, False, input_dim, num_output_classes)\n\neval_minibatch_size = 25\neval_input_map = {x: reader_eval.streams.features, y:reader_eval.streams.labels} \n\ndata = reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n\nimg_label = data[y].asarray()\nimg_data = data[x].asarray()\n\n# reshape img_data to: M x 1 x 28 x 28 to be compatible with model\nimg_data = np.reshape(img_data, (eval_minibatch_size, 1, 28, 28))\n\npredicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Find the index with the maximum value for both predicted as well as the ground truth\npred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\ngtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Label    :\", gtlabel[:25])\nprint(\"Predicted:\", pred)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Label    : [7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4]\nPredicted: [7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Plot a random image\nsample_number = 5\nplt.imshow(img_data[sample_number].reshape(28,28), cmap=\"gray_r\")\nplt.axis('off')\n\nimg_gt, img_pred = gtlabel[sample_number], pred[sample_number]\nprint(\"Image Label: \", img_pred)",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Image Label:  1\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAABRNJREFUeJzt3a9uFF0cgOEuLaQoEFhA4UhISMCQ4GpBI7AkRXERwA1wGSQYFBJCapAEh0CAbHAkpGI/89k5JTvZ/tn3eeyvc2aT8nLE2ZkulsvlFtBz4bQ/AHA6xA9R4oco8UOU+CFK/BAlfogSP0SJH6J2Tvh+vk4I67f4lx+y80OU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfonZO+wOw2d6/fz85e/To0fDaN2/eDOf7+/vD+fb29nBeZ+eHKPFDlPghSvwQJX6IEj9EiR+iFsvl8iTvd6I3Y/0ODw+H8zt37kzOfv36Nevef/78Gc4vX748a/1zbPEvP2TnhyjxQ5T4IUr8ECV+iBI/RHmkl1k+ffo0nM85znvy5Mlwvru7u/La2PkhS/wQJX6IEj9EiR+ixA9R4oco5/wM/f37dzh/+fLl2u799OnT4Xyx+KcnV5lg54co8UOU+CFK/BAlfogSP0SJH6K8upuhL1++DOf3799fee2dnfHXTI6OjlZeO86ru4Fp4oco8UOU+CFK/BAlfogSP0R5np+hd+/erW3tvb29ta3N8ez8ECV+iBI/RIkfosQPUeKHKPFDlHN+hj5+/Djr+kuXLk3OXr9+PWtt5rHzQ5T4IUr8ECV+iBI/RIkfory6O+7g4GA4f/Dgwaz1r169Ojn7/fv3rLWZ5NXdwDTxQ5T4IUr8ECV+iBI/RIkfojzSG3fcn+Cea39/f63rszo7P0SJH6LED1HihyjxQ5T4IUr8EOWcP27uOf/oef2tra2t58+fz1qf9bHzQ5T4IUr8ECV+iBI/RIkfosQPUd7bv+E+f/48nD98+HA4P+7fx82bN4fzHz9+DOeshff2A9PED1HihyjxQ5T4IUr8ECV+iPI8/4Y7PDwczud+z2Nvb2/W9ZweOz9EiR+ixA9R4oco8UOU+CHKUd+Ge/v27azrj3s197Nnz2atz+mx80OU+CFK/BAlfogSP0SJH6LED1Fe3b0Bfv78OTm7cePG8Nrjfv+3b98ezr9+/Tqccyq8uhuYJn6IEj9EiR+ixA9R4oco8UOU5/k3wMHBweRs7vc4Hj9+POt6zi47P0SJH6LED1HihyjxQ5T4IUr8EOWcfwMc92e4R65duzacv3jxYuW1Odvs/BAlfogSP0SJH6LED1HihyhHfRvgw4cPK197/fr14fzKlSsrr83ZZueHKPFDlPghSvwQJX6IEj9EiR+inPOfA0dHR8P59+/fV157d3d3OL948eLKa3O22fkhSvwQJX6IEj9EiR+ixA9R4oco5/znwIUL4/+j7927Nzn79u3b8Npbt26t9Jk4/+z8ECV+iBI/RIkfosQPUeKHKPFDlHP+c2B7e3s4f/Xq1eRssVgMr7179+5Kn4nzz84PUeKHKPFDlPghSvwQJX6IEj9ELZbL5Une70RvBlHjL3f8z84PUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iDrpP9H9T68UBtbPzg9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9E/Qdk0Id4759HOgAAAABJRU5ErkJggg==\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7f850c6d2e10>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Modify this model\ndef create_model(features):\n    with C.layers.default_options(init = C.glorot_uniform(), activation = C.relu):\n            h = features\n            \n            h = C.layers.Convolution2D(filter_shape=(5,5), \n                                       num_filters=8, \n                                       strides=(2,2), \n                                       pad=True, name='first_conv')(h)\n            h = C.layers.Convolution2D(filter_shape=(5,5), \n                                       num_filters=16, \n                                       strides=(2,2), \n                                       pad=True, name='second_conv')(h)\n            r = C.layers.Dense(num_output_classes, activation = None, name='classify')(h)\n            return r\n        \n# do_train_test()",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}